{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression - Position vs Salary\n",
    "This notebook if for you to learn the basics of Polynomial Regression. We will use the Position vs Salary dataset to understand how to implement Polynomial Regression in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will see that we are going to use the `LinearRegression` class from the `sklearn.linear_model` module to train the model. This is where the \"AI\" will be taking place.\n",
    "\n",
    "In order to use it you will need to install the following library into your Python virtual environment.\n",
    "\n",
    "First you will want to activate your virtual environment in your terminal (if your virtual terminal is not running). If you do not see the green (.venv) in your terminal, you will need to activate it.\n",
    "\n",
    "This is how you activate it on PC:\n",
    "```bash\n",
    ".venv\\Scripts\\activate\n",
    "```\n",
    "\n",
    "Once it is activated, you can install the library by running the following command in your terminal:\n",
    "\n",
    "```bash\n",
    "pip install scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('data/Position_Salaries.csv')\n",
    "\n",
    "X = dataset.iloc[:, 1:-1].values \n",
    "y = dataset.iloc[:, 2].values \n",
    "print(X)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression() # We are choosing the LinearRegression class\n",
    "regressor.fit(X, y) # We are fitting the regressor object to our data. \"Fitting\" is also called \"training\" the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color = 'red') # We are plotting the real data\n",
    "plt.plot(X, regressor.predict(X), color = 'blue') # We are plotting the predicted data\n",
    "plt.title('Position Level vs Salary')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"straight line\" of the Linear Regression does not seem to fit the data very well. We can see that the data is more of a curve. This is where Polynomial Regression comes in. It is a form of regression analysis in which the relationship between the independent variable x and the dependent variable y is modelled as an nth degree polynomial in x.\n",
    "\n",
    "We would call this underfitting. Underfitting is when the model is too simple to fit the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly_reg = PolynomialFeatures(degree = 4)\n",
    "X_poly = poly_reg.fit_transform(X)\n",
    "lin_reg_2 = LinearRegression()\n",
    "lin_reg_2.fit(X_poly, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X, y, color = 'red')\n",
    "plt.plot(X, lin_reg_2.predict(poly_reg.fit_transform(X)), color = 'blue')\n",
    "plt.title('Position Level vs Salary')\n",
    "plt.xlabel('Position Level')\n",
    "plt.ylabel('Salary')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhere between 2 and 4 degrees of polynomial should be a good fit for this dataset.\n",
    "\n",
    "The more we increase the degree of the polynomial, the more complex the model will be. This can lead to overfitting. Overfitting is when the model is too complex to fit the data. If others words, it is not abstract enough to generalize the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
